{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project - ECG Arrhythmia Classification\n",
    "### Natalia Kolińska, Alicja Smaruj, Dorota Woźna, Kacper Zielak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Załadowanie pakietów\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import missingno as msno\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Load data\n",
    "Source: [Kaggle](https://www.kaggle.com/datasets/sadmansakib7/ecg-arrhythmia-classification-dataset?select=Sudden+Cardiac+Death+Holter+Database.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"data/INCART 2-lead Arrhythmia Database.csv\")\n",
    "df_2 = pd.read_csv(\"data/MIT-BIH Arrhythmia Database.csv\")\n",
    "df_3 = pd.read_csv(\"data/MIT-BIH Supraventricular Arrhythmia Database.csv\")\n",
    "test_data = pd.read_csv(\"data/Sudden Cardiac Death Holter Database.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat([df_1, df_2, df_3])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dependent variable\n",
    "- N (Normal),\n",
    "- SVEB (Supraventricular ectopic beat),\n",
    "- VEB (Ventricular ectopic beat),\n",
    "- F (Fusion beat),\n",
    "- Q (Unknown beat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data.groupby(\"type\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data.groupby(\"type\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór danych zawiera cechy utworzone na podstawie wynikow EKG serca. Podawane są wysokości lub szerokości wyliczone między specyficznymi momentami w szeregu czasowym. Pozwala to na zastosowanie uczenia maszynowego do klasyfikacji szeregów czasowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/wykres_ecg.png\" alt=\"Wykres\" width=\"400\"/>\n",
    "<img src=\"images/prepost.png\" alt=\"Wykres2\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autorzy zbioru utworzyli 16 zmiennych. Zbadali je na surowych szeregach czasowych (a) oraz przetworzonych szeregach na których usunięto szum (b).Stąd 32 kolumny z pomiarami. Surowe dane mają przedrostek '0' a przetworzone '1'.\n",
    "\n",
    "<img src=\"images/LeadAB.png\" alt=\"Wykres2\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check if anything is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check how many percentage are null values in test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "round(test_data.isnull().sum() * 100 / len(test_data), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check if outliers influence arrhythmia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Q1:\",\n",
    "    train_data[\"0_pPeak\"].quantile(0.25),\n",
    "    \"Q2:\",\n",
    "    train_data[\"0_pPeak\"].quantile(0.5),\n",
    "    \"Q3:\",\n",
    "    train_data[\"0_pPeak\"].quantile(0.75),\n",
    ")\n",
    "print(\"Min:\", min(train_data[\"0_pPeak\"]), \"Max:\", max(train_data[\"0_pPeak\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q3 = train_data[\"0_pPeak\"].quantile(0.75)\n",
    "print(\"Amount of outliers:\", len(train_data.loc[train_data[\"0_pPeak\"] > q3]))\n",
    "print(\"Percentage of type in the outlier group\")\n",
    "train_data.loc[train_data[\"0_pPeak\"] > q3].groupby(\"type\").size() * 100 / len(train_data.loc[train_data[\"0_pPeak\"] > q3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jest bardzo dużo outlierów, ale czy powinniśmy je usunąć lub zastąpić? Możliwe, że to były mocniejsze uderzenia serca u zdrowych osób."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Remove 'record' column, because the name of the subject/patient is irrelevant in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(\"record\", axis=1)\n",
    "test_data = test_data.drop(\"record\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Remove null observations from test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data = test_data.dropna()\n",
    "# len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"type\"]\n",
    "X_train = train_data.drop(columns=[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data[\"type\"]\n",
    "X_test = test_data.drop(columns=[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr()\n",
    "plt.figure(figsize=(9,7))\n",
    "sns.set_theme(\"notebook\")\n",
    "sns.set_palette(\"PuBuGn_d\")\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", annot=False)\n",
    "plt.savefig(\"images/corplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data0 = train_data[[\"type\", *[column_name for column_name in train_data.columns if column_name.startswith(\"0_\")]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data[[\"type\", *[column_name for column_name in train_data.columns if column_name.startswith(\"1_\")]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykresy pudełkowe dla danych surowych (0) i przefiltrowanych (1) podzielone na grupy:\n",
    "* pre-RR i post-RR\n",
    "* peaks\n",
    "* intervals\n",
    "* morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zbudowanie wykresów pudełkowych trwa ok. 3 minuty.\n",
    "# Jeśli nie potrzebujesz wersji interaktywnej, możesz skorztstać z zapisanych obrazów. \n",
    "\n",
    "prepost_0=[\"0_pre-RR\", \"0_post-RR\"]\n",
    "data_to_box_0 = pd.melt(train_data0[[\"type\", *prepost_0]], id_vars=\"type\", value_vars=prepost_0)\n",
    "fig1 = px.box(data_to_box_0, y=\"value\", x=\"variable\", color=\"type\", width=1000)\n",
    "fig1.write_image(\"images/box_RR_0.png\")\n",
    "\n",
    "prepost_1=[\"1_pre-RR\", \"1_post-RR\"]\n",
    "data_to_box_1 = pd.melt(train_data1[[\"type\", *prepost_1]], id_vars=\"type\", value_vars=prepost_1)\n",
    "fig2 = px.box(data_to_box_1, y=\"value\", x=\"variable\", color=\"type\", width=1000)\n",
    "fig2.write_image(\"images/box_RR_1.png\")\n",
    "\n",
    "peaks_0=[\"0_pPeak\", \"0_tPeak\", \"0_rPeak\", \"0_sPeak\", \"0_qPeak\"]\n",
    "data_to_box_3 = pd.melt(train_data0[[\"type\",*peaks_0]], id_vars=\"type\", value_vars=peaks_0)\n",
    "fig3= px.box(data_to_box_3, y=\"value\", x=\"variable\", color=\"type\", width=1000)\n",
    "fig3.write_image(\"images/box_peaks_0.png\")\n",
    "\n",
    "peaks_1=[\"1_pPeak\", \"1_tPeak\", \"1_rPeak\", \"1_sPeak\", \"1_qPeak\"]\n",
    "data_to_box4 = pd.melt(train_data1[[\"type\", *peaks_1]], id_vars=\"type\", value_vars=peaks_1)\n",
    "fig4= px.box(data_to_box4, y=\"value\", x=\"variable\", color=\"type\", width=1000)\n",
    "fig4.write_image(\"images/box_peaks_1.png\")\n",
    "\n",
    "intervals_0=[\"0_qrs_interval\", \"0_pq_interval\", \"0_qt_interval\", \"0_st_interval\"]\n",
    "data_to_box5 = pd.melt(train_data0[[\"type\", *intervals_0]], id_vars=\"type\", value_vars=intervals_0)\n",
    "fig5 = px.box(data_to_box5, y=\"value\", x=\"variable\", color=\"type\", width=1000)\n",
    "fig5.write_image(\"images/box_intervals_0.png\")\n",
    "\n",
    "intervals_1=[\"1_qrs_interval\", \"1_pq_interval\", \"1_qt_interval\", \"1_st_interval\"]\n",
    "data_to_box6 = pd.melt(train_data1[[\"type\", *intervals_1]], id_vars=\"type\", value_vars=intervals_1)\n",
    "fig6 = px.box(data_to_box6, y=\"value\", x=\"variable\", color=\"type\", width=1000)\n",
    "fig6.write_image(\"images/box_intervals_1.png\")\n",
    "\n",
    "morphs_0=[\"0_qrs_morph0\", \"0_qrs_morph1\", \"0_qrs_morph2\", \"0_qrs_morph3\", \"0_qrs_morph4\",]\n",
    "data_to_box7 = pd.melt(train_data0[[\"type\", *morphs_0]], id_vars=\"type\", value_vars=morphs_0)\n",
    "fig7 = px.box(data_to_box7, y=\"value\", x=\"variable\", color=\"type\")\n",
    "fig7.write_image(\"images/box_morphs_0.png\")\n",
    "\n",
    "morphs_1=[\"1_qrs_morph0\", \"1_qrs_morph1\", \"1_qrs_morph2\", \"1_qrs_morph3\", \"1_qrs_morph4\",]\n",
    "data_to_box8 = pd.melt(train_data1[[\"type\", *morphs_1]], id_vars=\"type\", value_vars=morphs_1)\n",
    "fig8 = px.box(data_to_box8, y=\"value\", x=\"variable\", color=\"type\")\n",
    "fig8.write_image(\"images/box_morphs_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standaryzacja oryginalnych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_all = StandardScaler()\n",
    "train_data_std = std_all.fit_transform(X_train)\n",
    "train_data_std = pd.DataFrame(train_data_std, columns=X_train.columns)\n",
    "\n",
    "test_data_std = std_all.transform(X_test)\n",
    "test_data_std = pd.DataFrame(test_data_std, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(train_data_std)\n",
    "\n",
    "fig = px.scatter(components, x=0, y=1, color=y_train, width=800)\n",
    "fig.write_image(\"images/pca_2d.png\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stworzono \"głupi\" model, który będzie służył do porównań, czy nasze modele uzyskują lepsze wyniki. Przyjęto strategię most-frequent, co będzie skutkowało zaklysyfikowaniem wszystkich obserwacji jako N (normalne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_model.fit(train_data_std, y_train)\n",
    "y_pred = dummy_model.predict(test_data_std)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced accuracy:\", balanced_accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\", zero_division=np.nan)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "print(\"Sensitivity (recall):\", recall)\n",
    "\n",
    "# specificity = specificity_score(y_test, y_pred)\n",
    "# print(\"Specificity :\", specificity, average=\"weighted\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Model 1 - Natalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Model 2 - Dorota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Krok 1: Stworzenie nowych zmiennych i zbadanie istotności ich wpływu na rozróżnienie grup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na podstawie wykresów pudełkowych box_RR_0 i box_RR_1 można zauważyć, że w przypadku zaburzenia SVEB, preRR jest często krótsze niż postRR,\n",
    "# dlatego dodano dwie zmienne opisujące ich różnice.\n",
    "data_new=pd.DataFrame()\n",
    "data_new[\"0_RR_diff\"] = X_train[\"0_pre-RR\"] - X_train[\"0_post-RR\"]\n",
    "data_new[\"1_RR_diff\"] = X_train[\"1_pre-RR\"] - X_train[\"1_post-RR\"]\n",
    "data_new[\"type\"] =  y_train\n",
    "\n",
    "def perform_dunn_test(data, column, group=\"type\", p_adjust=\"fdr_bh\"):\n",
    "    dunn_df = posthoc_dunn(data, val_col=column, group_col=group, p_adjust=p_adjust)\n",
    "    remove = np.tril(np.ones(dunn_df.shape), k=0).astype(bool)\n",
    "    dunn_df[remove] = np.nan\n",
    "    molten_df = dunn_df.melt(ignore_index=False).reset_index().dropna()\n",
    "    molten_df.rename(columns={\"value\": f\"{column}_sign\"}, inplace=True)\n",
    "    return molten_df\n",
    "\n",
    "molten_df1 = perform_dunn_test(data_new, \"0_RR_diff\")\n",
    "molten_df2 = perform_dunn_test(data_new, \"1_RR_diff\")\n",
    "\n",
    "dunn_summ = pd.merge(molten_df1, molten_df2)\n",
    "\n",
    "# wskazanie istotnych\n",
    "def color_red(val):\n",
    "    color = \"red\" if val <= 0.05 else \"black\"\n",
    "    return f\"color: {color}\"\n",
    "\n",
    "# Stworzenie obiektu Styler i zastosowanie funkcji do kolumny \"0_RR_diff\"\n",
    "dunn_summ = dunn_summ.style.applymap(color_red, subset=[\"0_RR_diff_sign\",\t\"1_RR_diff_sign\"])\n",
    "dunn_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższe wyniki potwierdzają, że nowo utworzone zmienne istotnie różnicują wszystkie pary typów poza F i N. Następnie przeprowadzimy standaryzację dla nowych zmiennych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Krok 2: pre-processing danych treningowych i testowych z nowymi zmiennymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"0_RR_diff\"] = X_train[\"0_pre-RR\"] - X_train[\"0_post-RR\"]\n",
    "X_train[\"1_RR_diff\"] = X_train[\"1_pre-RR\"] - X_train[\"1_post-RR\"]\n",
    "\n",
    "X_test[\"0_RR_diff\"] = X_test[\"0_pre-RR\"] - X_test[\"0_post-RR\"]\n",
    "X_test[\"1_RR_diff\"] = X_test[\"1_pre-RR\"] - X_test[\"1_post-RR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline= Pipeline(\n",
    "    [\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_prep = pipeline.fit_transform(X_train)\n",
    "test_data_prep = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Krok 3: Budowa drzew decyzyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# drzewo decyzyjne z walidacją krzyżową i zbalansowaniem klas przy podziale na treningowe i testowe\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "ma_train = []\n",
    "ma_test = []\n",
    "for j in range(1, 21):\n",
    "    model = tree.DecisionTreeClassifier(random_state=10, max_depth=j)\n",
    "    a_test = []\n",
    "    a_tren = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(train_data_prep, y_train)):\n",
    "        model.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "        a_test.append(model.score(X_train.iloc[test_index], y_train.iloc[test_index]).round(4))\n",
    "        a_tren.append(model.score(X_train.iloc[train_index], y_train.iloc[train_index]).round(4))\n",
    "\n",
    "    ma_test.append(np.mean(a_test))\n",
    "    ma_train.append(np.mean(a_tren))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wybór głębokości drzewa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(1, 21)\n",
    "plt.plot(depths, ma_test, label=\"Train Accuracy\", color=\"blue\")\n",
    "plt.plot(depths, ma_train, label=\"Test Accuracy\", color=\"red\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.xticks(range(21))\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"Grid Search Results for Decision Tree\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"images/grid_search_trees.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wybrano głębokość drzewa równą 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zbudowanie modelu na wszystkich danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=10, max_depth=8)\n",
    "model.fit(train_data_prep, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ocena dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_data_prep)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced accuracy:\", balanced_accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "print(\"Sensivity (recall):\", recall)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types=np.unique(y_test.values)\n",
    "conf_matrix=pd.DataFrame(confusion_matrix(y_test, y_pred, labels=types), columns=types, index=types)\n",
    "percentage=conf_matrix.div(conf_matrix.sum(axis=1), axis=0)\n",
    "percentage = percentage.fillna(0)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(percentage, fmt='.2%', annot=True, annot_kws={\"size\": 12})\n",
    "plt.xlabel(\"Predicted label\");\n",
    "plt.ylabel(\"True label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obserwacje typu F były w 92,86% przypadków mylone jako N.\n",
    "99,39% wartości normalnych jest prawidłowo zaklysyfikowanych.\n",
    "Żadna obserwacja typu Q nie została zaklasyfikowana poprawnie. Często były mylone z N lub SVEB.\n",
    "Obserwacje typu SVEB były w 97,01% przypadków mylone z N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zmienne istotne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeksy = np.where(model.feature_importances_!=0)[0]\n",
    "variables= [X_train.columns[i] for i in indeksy]\n",
    "importances = model.feature_importances_[indeksy]\n",
    "\n",
    "# sortowanie\n",
    "importances, variables= zip(*sorted(zip(importances, variables), reverse=False))\n",
    "\n",
    "# Tworzenie wykresu słupkowego z niezerowymi wartościami\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plt.barh(variables[:15], importances[:15])\n",
    "\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Model 3 - Kacper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
